{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fTjIAbgNGIc8",
        "outputId": "000e9776-2f6d-4c20-ce0f-38748b31d092"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Performance Accuracy:\n",
            "                                 Sample_1  Sample_2  Sample_3  Sample_4  \\\n",
            "Logistic Regression             0.935484  0.918033  0.869565  0.844262   \n",
            "Random Forest (default)         0.967742  0.983607  0.956522  1.000000   \n",
            "SVC (linear kernel)             0.967742  0.885246  0.847826  0.868852   \n",
            "SVC (RBF kernel)                0.548387  0.721311  0.673913  0.655738   \n",
            "Random Forest (200 estimators)  0.967742  0.983607  0.956522  0.991803   \n",
            "\n",
            "                                Sample_5  \n",
            "Logistic Regression             0.875817  \n",
            "Random Forest (default)         1.000000  \n",
            "SVC (linear kernel)             0.921569  \n",
            "SVC (RBF kernel)                0.660131  \n",
            "Random Forest (200 estimators)  1.000000  \n",
            "The best performing model is: Random Forest (default) with maximum accuracy across all samples.\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "\n",
        "# Load dataset\n",
        "df = pd.read_csv('/content/Creditcard_data.csv')\n",
        "\n",
        "# Function to balance the dataset using different techniques\n",
        "def balance_dataset(features, labels, technique=\"SMOTE\"):\n",
        "    \"\"\"\n",
        "    Balances the dataset using the specified technique (SMOTE or undersampling).\n",
        "    \"\"\"\n",
        "    if technique == \"SMOTE\":\n",
        "        smote = SMOTE(random_state=42)\n",
        "        features_resampled, labels_resampled = smote.fit_resample(features, labels)\n",
        "    elif technique == \"undersampling\":\n",
        "        rus = RandomUnderSampler(random_state=42)\n",
        "        features_resampled, labels_resampled = rus.fit_resample(features, labels)\n",
        "    else:\n",
        "        raise ValueError(\"Unknown balancing technique specified\")\n",
        "    return features_resampled, labels_resampled\n",
        "\n",
        "# Separate features and labels\n",
        "X_features = df.drop(\"Class\", axis=1)\n",
        "y_labels = df[\"Class\"]\n",
        "\n",
        "# Apply balancing\n",
        "X_resampled, y_resampled = balance_dataset(X_features, y_labels)\n",
        "\n",
        "# Create different sample sizes\n",
        "sample_sizes = [int(len(X_resampled) * 0.1 * i) for i in range(1, 6)]\n",
        "sampled_data = [X_resampled.sample(n=size, random_state=42) for size in sample_sizes]\n",
        "sampled_labels = [y_resampled.iloc[sample.index] for sample in sampled_data]\n",
        "\n",
        "# Define models\n",
        "models_dict = {\n",
        "    \"Logistic Regression\": LogisticRegression(),\n",
        "    \"Random Forest (default)\": RandomForestClassifier(),\n",
        "    \"SVC (linear kernel)\": SVC(kernel=\"linear\"),\n",
        "    \"SVC (RBF kernel)\": SVC(kernel=\"rbf\"),\n",
        "    \"Random Forest (200 estimators)\": RandomForestClassifier(n_estimators=200)\n",
        "}\n",
        "\n",
        "# Store results\n",
        "accuracy_results = {}\n",
        "\n",
        "# Loop over the sampled data and models to calculate accuracy\n",
        "for index, (X_sample, y_sample) in enumerate(zip(sampled_data, sampled_labels)):\n",
        "    sample_name = f\"Sample_{index+1}\"\n",
        "    for model_name, model in models_dict.items():\n",
        "\n",
        "        # Split into training and test sets\n",
        "        X_train, X_test, y_train, y_test = train_test_split(X_sample, y_sample, test_size=0.2, random_state=42)\n",
        "\n",
        "        # Train the model\n",
        "        model.fit(X_train, y_train)\n",
        "\n",
        "        # Make predictions and calculate accuracy\n",
        "        predictions = model.predict(X_test)\n",
        "        accuracy = accuracy_score(y_test, predictions)\n",
        "\n",
        "        # Store the result in a dictionary\n",
        "        if model_name not in accuracy_results:\n",
        "            accuracy_results[model_name] = {}\n",
        "        accuracy_results[model_name][sample_name] = accuracy\n",
        "\n",
        "# Convert results to DataFrame for easier readability\n",
        "accuracy_df = pd.DataFrame(accuracy_results).T\n",
        "print(\"Model Performance Accuracy:\\n\", accuracy_df)\n",
        "\n",
        "# Identify the best model and its performance across samples\n",
        "best_model = accuracy_df.max(axis=1).idxmax()\n",
        "print(f\"The best performing model is: {best_model} with maximum accuracy across all samples.\")\n"
      ]
    }
  ]
}